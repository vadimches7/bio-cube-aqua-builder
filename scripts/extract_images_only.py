#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¢–û–õ–¨–ö–û –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –æ —Ä—ã–±–∞—Ö
–ù–µ –ø–∞—Ä—Å–∏—Ç —Å—Ç–∞—Ç—å–∏ –∑–∞–Ω–æ–≤–æ, —Ç–æ–ª—å–∫–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
"""

import requests
from bs4 import BeautifulSoup
import time
import json
import re
from urllib.parse import urljoin
from pathlib import Path
from typing import Optional

BASE_DIR = Path(__file__).parent.parent
CATALOG_PATH = BASE_DIR / 'fish_catalog.json'
OUTPUT_PATH = BASE_DIR / 'fish_catalog.json'  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª

BASE_URL = "https://fanfishka.ru"
DELAY_BETWEEN_REQUESTS = 1

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def get_page(url: str, retries: int = 3) -> Optional[BeautifulSoup]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            response.raise_for_status()
            response.encoding = 'utf-8'
            return BeautifulSoup(response.text, 'html.parser')
        except requests.RequestException as e:
            if attempt < retries - 1:
                time.sleep(2)
            else:
                return None
    return None

def extract_image_from_page(soup: BeautifulSoup) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á—å –≥–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä—ã–±—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞"""
    image_url = None
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ò—â–µ–º –≥–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –∫–∞—Ä—Ç–æ—á–∫–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–∞—Ç–∞–ª–æ–≥–∞
    # –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –≥–ª–∞–≤–Ω–æ–µ —Ñ–æ—Ç–æ –æ–±—ã—á–Ω–æ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –∫–∞—Ä—Ç–æ—á–∫–∏
    card_selectors = [
        '.post-box img',
        '.article-item img',
        '.post-card img',
        '.fish-card img',
        '.item img',
        '.card img',
        'article img:first-of-type',
        '.entry-thumbnail img',
        '.post-thumbnail img',
        '.featured-image img',
        'img[class*="fish"]',
        'img[class*="ryb"]'
    ]
    
    for selector in card_selectors:
        img = soup.select_one(selector)
        if img:
            img_src = (img.get('src') or 
                      img.get('data-src') or 
                      img.get('data-lazy-src') or
                      img.get('data-original') or
                      img.get('data-url'))
            
            if img_src:
                img_src = urljoin(BASE_URL, img_src)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –±–∞–Ω–Ω–µ—Ä—ã
                skip_default = [
                    'sovmestimost_akvaryb.png',
                    '–±–∞–Ω–Ω–µ—Ä',
                    'banner',
                    'navigator',
                    '—Ä–µ–∫–ª–∞–º'
                ]
                if any(skip in img_src.lower() for skip in skip_default):
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∫–æ–Ω–∫–∏ –∏ –ª–æ–≥–æ—Ç–∏–ø—ã
                skip_patterns = [
                    'logo', 'icon', 'avatar', 'thumb', 
                    'thumbnail', 'wp-', 'emoji', 'button', 'arrow',
                    'social', 'share', 'comment', 'widget'
                ]
                if any(skip in img_src.lower() for skip in skip_patterns):
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
                width = img.get('width') or img.get('data-width') or '0'
                try:
                    w = int(str(width).replace('px', ''))
                    if w > 200:  # –¢–æ–ª—å–∫–æ –±–æ–ª—å—à–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        image_url = img_src
                        break
                except:
                    # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –Ω–µ —É–∫–∞–∑–∞–Ω, –Ω–æ —ç—Ç–æ –Ω–µ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ - –±–µ—Ä–µ–º
                    if 'sovmestimost' not in img_src.lower():
                        image_url = img_src
                        break
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ò—â–µ–º –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü —Å—Ç–∞—Ç–µ–π)
    if not image_url:
        content_containers = [
            '.entry-content',
            '.post-content',
            '.article-content',
            '.content',
            'article',
            '.post-body',
            '.single-post',
            'main article',
            '.article-body'
        ]
        
        for container_selector in content_containers:
            container = soup.select_one(container_selector)
            if container:
                images = container.find_all('img')
                for img in images:
                    img_src = (img.get('src') or 
                              img.get('data-src') or 
                              img.get('data-lazy-src') or
                              img.get('data-original') or
                              img.get('data-url'))
                    
                    if img_src:
                        img_src = urljoin(BASE_URL, img_src)
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        if 'sovmestimost_akvaryb.png' in img_src.lower():
                            continue
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∫–æ–Ω–∫–∏ –∏ –ª–æ–≥–æ—Ç–∏–ø—ã
                        skip_patterns = [
                            'logo', 'icon', 'avatar', 'banner', 'thumb', 
                            'thumbnail', 'wp-', 'emoji', 'button', 'arrow',
                            'social', 'share', 'comment', 'widget'
                        ]
                        if any(skip in img_src.lower() for skip in skip_patterns):
                            continue
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
                        width = img.get('width') or img.get('data-width') or '0'
                        try:
                            w = int(str(width).replace('px', ''))
                            if w > 200:  # –¢–æ–ª—å–∫–æ –±–æ–ª—å—à–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                image_url = img_src
                                break
                        except:
                            # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –Ω–µ —É–∫–∞–∑–∞–Ω, –Ω–æ —ç—Ç–æ –Ω–µ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ - –±–µ—Ä–µ–º
                            if 'sovmestimost' not in img_src.lower():
                                image_url = img_src
                                break
                
                if image_url:
                    break
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –±–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ
    if not image_url:
        all_images = soup.find_all('img')
        candidate_images = []
        
        for img in all_images:
            img_src = (img.get('src') or 
                      img.get('data-src') or 
                      img.get('data-lazy-src') or
                      img.get('data-original'))
            
            if img_src:
                img_src = urljoin(BASE_URL, img_src)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
                if 'sovmestimost' in img_src.lower():
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∫–æ–Ω–∫–∏
                skip_patterns = ['logo', 'icon', 'avatar', 'banner', 'thumb', 'wp-admin', 'social']
                if any(skip in img_src.lower() for skip in skip_patterns):
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä
                width = img.get('width') or img.get('data-width') or '0'
                height = img.get('height') or img.get('data-height') or '0'
                
                try:
                    w = int(str(width).replace('px', '')) if width else 0
                    h = int(str(height).replace('px', '')) if height else 0
                    size = w * h if w > 0 and h > 0 else 1000
                    candidate_images.append((size, img_src))
                except:
                    candidate_images.append((1000, img_src))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ –±–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ
        if candidate_images:
            candidate_images.sort(reverse=True, key=lambda x: x[0])
            image_url = candidate_images[0][1]
    
    return image_url

def is_fish_article(item: dict) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç–∞—Ç—å—è –æ —Ä—ã–±–µ"""
    name = item.get('name_ru', '').lower()
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ-—Ä—ã–±—ã
    exclude_keywords = [
        '—Ä–∞—Å—Ç–µ–Ω–∏', '–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω', '—Ñ–∏–ª—å—Ç—Ä', '–æ–±–æ–≥—Ä–µ–≤–∞—Ç–µ–ª', '–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä',
        '–æ—Å–≤–µ—â–µ–Ω', '–≥—Ä—É–Ω—Ç', '–¥–µ–∫–æ—Ä', '–∫–æ—Ä–º', '–ª–µ—á–µ–Ω', '–±–æ–ª–µ–∑–Ω',
        '—Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö', '–∫–∞—Ç–∞–ª–æ–≥', '–æ–±–∑–æ—Ä –≤–Ω–µ—à–Ω–µ–≥–æ', '—Å—Ç–∞—Ç—å', 
        '—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç –∞–∫–≤–∞—Ä–∏—É–º–Ω—ã—Ö'
    ]
    
    if any(keyword in name for keyword in exclude_keywords):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä—ã–±—ã
    has_fish_params = (
        item.get('size_cm', 0) > 0 or
        item.get('min_tank_liters', 0) > 0 or
        item.get('water_params', {}).get('temp_min') is not None
    )
    
    return has_fish_params

def reconstruct_url(item: dict) -> list:
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç URL —Å—Ç–∞—Ç—å–∏ –ø–æ ID –∏ –Ω–∞–∑–≤–∞–Ω–∏—é"""
    article_id = item.get('id')
    name = item.get('name_ru', '')
    
    if not article_id or not name:
        return []
    
    # –°–æ–∑–¥–∞–µ–º slug –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
    name_slug = name.lower()
    # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    name_slug = re.sub(r'[^\w\s-]', '', name_slug)
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –¥–µ—Ñ–∏—Å—ã
    name_slug = re.sub(r'\s+', '-', name_slug)
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    name_slug = name_slug[:50]
    
    # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ URL
    possible_urls = [
        f"https://fanfishka.ru/akvariumnye-stati/akvariumnye_rybki/{article_id}-{name_slug}.html",
        f"https://fanfishka.ru/akvariumnye-stati/akvariumnye_rybki/{article_id}.html",
    ]
    
    return possible_urls

def main():
    print("=" * 60)
    print("–ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –î–õ–Ø –ê–ö–í–ê–†–ò–£–ú–ù–´–• –†–´–ë")
    print("=" * 60)
    print()
    
    # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–∞—Ç–∞–ª–æ–≥
    print("üìñ –ß—Ç–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞...")
    with open(CATALOG_PATH, 'r', encoding='utf-8') as f:
        catalog_data = json.load(f)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(catalog_data)} –∑–∞–ø–∏—Å–µ–π")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç—å–∏ –æ —Ä—ã–±–∞—Ö
    fish_articles = [item for item in catalog_data if is_fish_article(item)]
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(fish_articles)} —Å—Ç–∞—Ç–µ–π –æ —Ä—ã–±–∞—Ö")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –±–∞–Ω–Ω–µ—Ä—ã
    articles_to_update = [
        item for item in fish_articles 
        if ('sovmestimost_akvaryb.png' in item.get('image_url', '').lower() or
            '–±–∞–Ω–Ω–µ—Ä' in item.get('image_url', '').lower() or
            'banner' in item.get('image_url', '').lower() or
            not item.get('image_url') or
            item.get('image_url', '').strip() == '')
    ]
    print(f"üì∏ –¢—Ä–µ–±—É—é—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(articles_to_update)}")
    print()
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    catalog_dict = {item['id']: item for item in catalog_data}
    
    # –ü–µ—Ä–µ–ø–∞—Ä—Å–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    updated_count = 0
    not_found_count = 0
    error_count = 0
    
    print("üîÑ –ù–∞—á–∞–ª–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
    print()
    
    for i, item in enumerate(articles_to_update, 1):
        article_id = item.get('id')
        fish_name = item.get('name_ru', 'N/A')[:40]
        
        print(f"[{i}/{len(articles_to_update)}] {fish_name}...")
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º URL
        possible_urls = reconstruct_url(item)
        if not possible_urls:
            print(f"   ‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å URL")
            error_count += 1
            continue
        
        image_found = False
        for url in possible_urls:
            soup = get_page(url)
            if soup:
                new_image = extract_image_from_page(soup)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∏ –Ω–µ –±–∞–Ω–Ω–µ—Ä
                if new_image and not any(skip in new_image.lower() for skip in ['sovmestimost', '–±–∞–Ω–Ω–µ—Ä', 'banner', 'navigator']):
                    catalog_dict[article_id]['image_url'] = new_image
                    updated_count += 1
                    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {new_image[:60]}...")
                    image_found = True
                    break
                elif soup:  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ
                    # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π URL
                    continue
            
            time.sleep(DELAY_BETWEEN_REQUESTS)
        
        if not image_found:
            not_found_count += 1
            print(f"   ‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 50 —Å—Ç–∞—Ç–µ–π
        if i % 50 == 0:
            with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
                json.dump(list(catalog_dict.values()), f, ensure_ascii=False, indent=2)
            print(f"\nüíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ({i} —Å—Ç–∞—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ)\n")
        
        time.sleep(DELAY_BETWEEN_REQUESTS)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(list(catalog_dict.values()), f, ensure_ascii=False, indent=2)
    
    print()
    print("=" * 60)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("=" * 60)
    print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {updated_count}")
    print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {not_found_count}")
    print(f"‚ö† –û—à–∏–±–∫–∏: {error_count}")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {OUTPUT_PATH}")
    print()
    print("‚ú® –ì–æ—Ç–æ–≤–æ!")

if __name__ == "__main__":
    main()

