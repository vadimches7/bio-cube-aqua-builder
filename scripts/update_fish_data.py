#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –æ–ø–∏—Å–∞–Ω–∏–π —Ä—ã–± –∏–∑ —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import json
import re
import os
from pathlib import Path

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
BASE_DIR = Path(__file__).parent.parent
CATALOG_PATH = BASE_DIR / 'fish_catalog.json'
FISH_DB_PATH = BASE_DIR / 'src' / 'data' / 'fishDatabase.ts'

print('üìñ –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...')

# –ß–∏—Ç–∞–µ–º —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
with open(CATALOG_PATH, 'r', encoding='utf-8') as f:
    catalog_data = json.load(f)

# –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
with open(FISH_DB_PATH, 'r', encoding='utf-8') as f:
    fish_db_content = f.read()

print(f'‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(catalog_data)} –∑–∞–ø–∏—Å–µ–π –≤ –∫–∞—Ç–∞–ª–æ–≥–µ')

# –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä—ã–± –∏–∑ BASE_FISH_DATABASE
fish_matches = []
# –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä—ã–±: id, name, nameEn
pattern = r"id:\s*['\"]([^'\"]+)['\"],\s*name:\s*['\"]([^'\"]+)['\"],\s*nameEn:\s*['\"]([^'\"]+)['\"]"

for match in re.finditer(pattern, fish_db_content):
    fish_matches.append({
        'id': match.group(1),
        'name': match.group(2),
        'nameEn': match.group(3),
        'start': match.start(),
        'end': match.end(),
    })

print(f'‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(fish_matches)} —Ä—ã–± –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö')

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π
def normalize_name(name):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    if not name:
        return ''
    return re.sub(r'[.,;:!?]', '', name.lower().strip().replace('\s+', ' '))

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
def find_match(fish, catalog):
    """–ù–∞—Ö–æ–¥–∏—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä—ã–±—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ"""
    fish_name_norm = normalize_name(fish['name'])
    fish_name_en_norm = normalize_name(fish['nameEn'])
    
    for item in catalog:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ-—Ä—ã–±—ã (—Ä–∞—Å—Ç–µ–Ω–∏—è, –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ)
        if not item.get('name_ru') or '—Ä–∞—Å—Ç–µ–Ω–∏' in item.get('name_ru', '').lower():
            continue
            
        item_name_norm = normalize_name(item.get('name_ru', ''))
        item_name_lat_norm = normalize_name(item.get('name_lat', ''))
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
        if item_name_norm and fish_name_norm and item_name_norm == fish_name_norm:
            return item
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ª–∞—Ç–∏–Ω—Å–∫–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
        if item_name_lat_norm and fish_name_en_norm and item_name_lat_norm == fish_name_en_norm:
            return item
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        fish_keywords = [w for w in fish_name_norm.split() if len(w) > 3]
        item_keywords = [w for w in item_name_norm.split() if len(w) > 3]
        
        if fish_keywords and item_keywords:
            common = set(fish_keywords) & set(item_keywords)
            if len(common) >= min(len(fish_keywords), len(item_keywords)) * 0.7:
                return item
    
    return None

# –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Ä—ã–±—ã
updates = []
not_found = []

# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
special_matches = {
    'neon-tetra': ['–Ω–µ–æ–Ω', 'neon'],
    'guppy': ['–≥—É–ø–ø–∏', 'guppy'],
    'angelfish': ['—Å–∫–∞–ª—è—Ä–∏—è', 'angelfish', 'pterophyllum'],
    'corydoras': ['–∫–æ—Ä–∏–¥–æ—Ä–∞—Å', 'corydoras'],
    'betta': ['–ø–µ—Ç—É—à–æ–∫', 'betta', '–±–æ–π—Ü–æ–≤'],
    'discus': ['–¥–∏—Å–∫—É—Å', 'discus'],
    'pleco': ['–ø–ª–µ–∫–æ', 'pleco', '–∞–Ω—Ü–∏—Å—Ç—Ä—É—Å'],
}

for fish in fish_matches:
    match = None
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    if fish['id'] in special_matches:
        keywords = special_matches[fish['id']]
        for item in catalog_data:
            item_name_lower = normalize_name(item.get('name_ru', ''))
            if any(kw in item_name_lower for kw in keywords):
                match = item
                break
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
    if not match:
        match = find_match(fish, catalog_data)
    
    if match:
        updates.append({
            'fish': fish,
            'catalog_item': match,
        })
        print(f'‚úÖ –ù–∞–π–¥–µ–Ω–æ: {fish["name"]} ‚Üî {match.get("name_ru", "N/A")}')
    else:
        not_found.append(fish)
        print(f'‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {fish["name"]}')

print(f'\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:')
print(f'   –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(updates)}')
print(f'   –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {len(not_found)}')

# –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª
updated_content = fish_db_content
backup_path = str(FISH_DB_PATH) + '.backup'

# –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø
with open(backup_path, 'w', encoding='utf-8') as f:
    f.write(fish_db_content)
print(f'\nüíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø: {backup_path}')

# –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —Ä—ã–±—É
for update in updates:
    fish = update['fish']
    catalog_item = update['catalog_item']
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
    if catalog_item.get('description_short'):
        description = catalog_item['description_short']
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        description = re.sub(r'\n+', ' ', description)
        description = re.sub(r'\s+', ' ', description).strip()
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ
        fish_name = fish['name']
        if description.lower().startswith(fish_name.lower()):
            # –£–±–∏—Ä–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞
            description = description[len(fish_name):].strip()
            # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞ –≤ –Ω–∞—á–∞–ª–µ
            words = description.split()
            if len(words) > 3:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –ª–∏ –Ω–∞—á–∞–ª–æ
                first_words = ' '.join(words[:3]).lower()
                if first_words in fish_name.lower() or fish_name.lower() in first_words:
                    description = ' '.join(words[3:])
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤
        if len(description) > 300:
            description = description[:300] + '...'
        
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª–µ—à–∏
        description = description.replace("\\", "\\\\").replace("'", "\\'")
        
        # –ò—â–µ–º –±–ª–æ–∫ —Å —ç—Ç–æ–π —Ä—ã–±–æ–π (–æ—Ç id –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏)
        fish_block_pattern = rf"(id:\s*['\"]{re.escape(fish['id'])}['\"][^}}]*?description:\s*['\"])([^'\"]*?)(['\"])"
        
        def replace_desc(m):
            return m.group(1) + description + m.group(3)
        
        updated_content = re.sub(fish_block_pattern, replace_desc, updated_content, flags=re.DOTALL)
        print(f'   ‚úì –û–±–Ω–æ–≤–ª–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è {fish["name"]}')
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image_url = catalog_item.get('image_url', '')
    if image_url and 'sovmestimost_akvaryb.png' not in image_url:
        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞ —Å —ç—Ç–æ–π —Ä—ã–±–æ–π
        fish_id_pattern = rf"id:\s*['\"]{re.escape(fish['id'])}['\"]"
        match_start = re.search(fish_id_pattern, updated_content)
        
        if match_start:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –±–ª–æ–∫–∞ (—Å–ª–µ–¥—É—é—â–∞—è –∑–∞–ø–∏—Å—å –∏–ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∞—è —Å–∫–æ–±–∫–∞)
            start_pos = match_start.start()
            # –ò—â–µ–º image: –≤ —ç—Ç–æ–º –±–ª–æ–∫–µ
            block_end = updated_content.find('},', start_pos)
            if block_end == -1:
                block_end = updated_content.find('}', start_pos)
            
            if block_end > start_pos:
                block = updated_content[start_pos:block_end]
                # –ò—â–µ–º image –≤ —ç—Ç–æ–º –±–ª–æ–∫–µ
                image_pattern = r"(image:\s*['\"])([^'\"]*)(['\"])"
                image_match = re.search(image_pattern, block)
                
                if image_match:
                    # –ó–∞–º–µ–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    old_image = image_match.group(2)
                    new_block = block[:image_match.start()] + image_match.group(1) + image_url + image_match.group(3) + block[image_match.end():]
                    updated_content = updated_content[:start_pos] + new_block + updated_content[block_end:]
                    print(f'   ‚úì –û–±–Ω–æ–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è {fish["name"]}: {image_url[:60]}...')
                else:
                    print(f'   ‚ö† –ù–µ –Ω–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω image –≤ –±–ª–æ–∫–µ {fish["name"]}')
            else:
                print(f'   ‚ö† –ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω–µ—Ü –±–ª–æ–∫–∞ –¥–ª—è {fish["name"]}')
        else:
            print(f'   ‚ö† –ù–µ –Ω–∞–π–¥–µ–Ω –±–ª–æ–∫ —Å id {fish["id"]}')

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
with open(FISH_DB_PATH, 'w', encoding='utf-8') as f:
    f.write(updated_content)
print(f'\n‚úÖ –§–∞–π–ª –æ–±–Ω–æ–≤–ª–µ–Ω: {FISH_DB_PATH}')

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
report = {
    'total': len(fish_matches),
    'found': len(updates),
    'not_found': [{'id': f['id'], 'name': f['name'], 'nameEn': f['nameEn']} for f in not_found],
    'updates': [
        {
            'fishId': u['fish']['id'],
            'fishName': u['fish']['name'],
            'catalogName': u['catalog_item'].get('name_ru', 'N/A'),
            'hasImage': bool(u['catalog_item'].get('image_url')),
            'hasDescription': bool(u['catalog_item'].get('description_short')),
        }
        for u in updates
    ],
}

report_path = BASE_DIR / 'scripts' / 'update_report.json'
with open(report_path, 'w', encoding='utf-8') as f:
    json.dump(report, f, ensure_ascii=False, indent=2)
print(f'üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}')

print(f'\n‚ú® –ì–æ—Ç–æ–≤–æ! –û–±–Ω–æ–≤–ª–µ–Ω–æ {len(updates)} –∏–∑ {len(fish_matches)} —Ä—ã–±')

